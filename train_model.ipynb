{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K779Uu40zjGR",
    "outputId": "57726b1a-5495-41aa-b9c7-9328cc447ce8"
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yF2fktBJ9fnt"
   },
   "source": [
    "# Data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iUkOGOp5CaA4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>antigramneg</th>\n",
       "      <th>antigrampos</th>\n",
       "      <th>bacteriano</th>\n",
       "      <th>cancer</th>\n",
       "      <th>fungico</th>\n",
       "      <th>microbiano</th>\n",
       "      <th>viral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHKKHTVYC</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GLGILFKGAAKGMSALLLLKCA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALGIIKGEAGKGLTC</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RKKKPYIIRP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NNQEGGVIGNGHR</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sequence  antigramneg  antigrampos  bacteriano  cancer  \\\n",
       "0               CHKKHTVYC            1            1           1       0   \n",
       "1  GLGILFKGAAKGMSALLLLKCA            1            1           1       0   \n",
       "2         ALGIIKGEAGKGLTC            1            1           1       0   \n",
       "3              RKKKPYIIRP            1            1           1       0   \n",
       "4           NNQEGGVIGNGHR            1            1           1       0   \n",
       "\n",
       "   fungico  microbiano  viral  \n",
       "0        1           1      0  \n",
       "1        1           1      0  \n",
       "2        1           1      0  \n",
       "3        1           1      0  \n",
       "4        1           1      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS = ['microbiano','bacteriano','antigramneg','antigrampos','fungico','viral','cancer']\n",
    "\n",
    "data_in = pd.read_csv('data/data_sample.csv')\n",
    "data_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_in.drop(LABELS, axis = 'columns')\n",
    "target = np.array(data_in[LABELS].values,dtype = \"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "data_ohe = encoding(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yDREg_u_Cbk-"
   },
   "outputs": [],
   "source": [
    "# Create tf.data.Dataset.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((tf.cast(data_ohe,dtype = tf.float32), target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZM3GSWoV3yxZ"
   },
   "outputs": [],
   "source": [
    "MATRIX_SHAPE = (data_ohe.shape[1],data_ohe.shape[2], 1)\n",
    "\n",
    "# Size of the noise vector\n",
    "LATENT_DIM = 200\n",
    "\n",
    "# Set the number of epochs for trainining.\n",
    "EPOCHS = 5 #100\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "NUM_CHANNELS = 1\n",
    "NUM_CLASSES = 7\n",
    "MATRIX_SIZE = (MATRIX_SHAPE[0],MATRIX_SHAPE[1])\n",
    "\n",
    "\n",
    "GENERATOR_IN_CHANNELS = LATENT_DIM + NUM_CLASSES\n",
    "DISCRIMINATOR_IN_CHANNELS = NUM_CHANNELS + NUM_CLASSES\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator_model():\n",
    "  \n",
    "  model = Sequential(name='generator')\n",
    "  model.add(Input(shape=(GENERATOR_IN_CHANNELS,)))\n",
    "  model.add(Reshape((1,GENERATOR_IN_CHANNELS)))\n",
    "  model.add(Bidirectional(layers.GRU(np.prod(MATRIX_SHAPE), return_sequences=True)))\n",
    "  model.add(Bidirectional(layers.GRU(np.prod(MATRIX_SHAPE))))\n",
    "  model.add(Dense(np.prod(MATRIX_SHAPE),activation='tanh'))\n",
    "  model.add(  Reshape((MATRIX_SHAPE[0],MATRIX_SHAPE[1],1))  )\n",
    "  model.summary()\n",
    "  return model\n",
    "\n",
    "# CREATE DISCRIMINATOR\n",
    "def create_discriminator_model():\n",
    "\n",
    "  d_model = Sequential(name='discriminator')\n",
    "  d_model.add(Input(shape=(MATRIX_SHAPE[0], MATRIX_SHAPE[1], DISCRIMINATOR_IN_CHANNELS)))\n",
    "  d_model.add(  Reshape(  (1, MATRIX_SHAPE[0] * MATRIX_SHAPE[1] * DISCRIMINATOR_IN_CHANNELS  )  )   )\n",
    "  d_model.add(Bidirectional(layers.GRU(np.prod(MATRIX_SHAPE))))\n",
    "  d_model.add(Dense(1, activation='sigmoid'))\n",
    "  d_model.summary()\n",
    "  return d_model\n",
    "\n",
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim, num_classes):\n",
    "        super(ConditionalGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def generate_class(self, n_gens,classes):\n",
    "      conditional_vector = []\n",
    "      for label in LABELS:\n",
    "        conditional_vector.append(1 if (label in classes) else 0)\n",
    "      conditional_vector\n",
    "      pred_gen = []\n",
    "      for i in range(n_gens):\n",
    "          lantent_dim_conditional_vector = np.concatenate(  (np.random.normal(0, 1, self.latent_dim) ,np.array(conditional_vector) )   ).reshape(1,-1)\n",
    "          gen_imgs = self.generator.predict(  lantent_dim_conditional_vector  )\n",
    "          output_sequence = ohe.inverse_transform(escalon_matrix(gen_imgs[0,:,:,0]))\n",
    "          output_sequence_str = \"\"\n",
    "          for i in output_sequence:\n",
    "              if str(i[0]) == '_':\n",
    "                #pass\n",
    "                break\n",
    "              else:\n",
    "                output_sequence_str += str(i[0])\n",
    "          pred_gen.append(output_sequence_str)\n",
    "      df_gen = pd.DataFrame({\"sequence\":pred_gen})\n",
    "      return df_gen\n",
    "\n",
    "    def generate_class_random(self, n_gens):\n",
    "      pred_gen = []\n",
    "      for i in range(n_gens):\n",
    "          lantent_dim_conditional_vector = np.concatenate(  (np.random.normal(0, 1, self.latent_dim) , np.random.randint(2, size=len(LABELS)) )   ).reshape(1,-1)\n",
    "          gen_imgs = self.generator.predict(  lantent_dim_conditional_vector  )\n",
    "          output_sequence = ohe.inverse_transform(escalon_matrix(gen_imgs[0,:,:,0]))\n",
    "          output_sequence_str = \"\"\n",
    "          for i in output_sequence:\n",
    "              if str(i[0]) == '_':\n",
    "                #pass\n",
    "                break\n",
    "              else:\n",
    "                output_sequence_str += str(i[0])\n",
    "          pred_gen.append(output_sequence_str)\n",
    "      df_gen = pd.DataFrame({\"sequence\":pred_gen})\n",
    "      return df_gen\n",
    "\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_matrix, one_hot_labels = data\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the matrixs. This is for the discriminator.\n",
    "        matrix_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        matrix_one_hot_labels = tf.repeat(\n",
    "            matrix_one_hot_labels, repeats=[MATRIX_SIZE[0] * MATRIX_SIZE[1]]\n",
    "        )\n",
    "        matrix_one_hot_labels = tf.reshape(\n",
    "            matrix_one_hot_labels, (-1, MATRIX_SIZE[0], MATRIX_SIZE[1], NUM_CLASSES)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_matrix)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake matrixs.\n",
    "        generated_matrix = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real matrixs. Note that we are concatenating the labels\n",
    "        # with these matrixs here.\n",
    "        fake_matrix_and_labels = tf.concat([generated_matrix, matrix_one_hot_labels], -1)\n",
    "  \n",
    "        #real_matrixs = tf.cast(real_matrixs,dtype = tf.float32)\n",
    "        real_matrix_and_labels = tf.concat([real_matrix, matrix_one_hot_labels], -1)\n",
    "        combined_matrixs = tf.concat(\n",
    "            [fake_matrix_and_labels, real_matrix_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake matrixs.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_matrixs)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real matrixs\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_matrixs = self.generator(random_vector_labels)\n",
    "            fake_matrix_and_labels = tf.concat([fake_matrixs, matrix_one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_matrix_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 1, 5880)           0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 1470)             29180970  \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1471      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,182,441\n",
      "Trainable params: 29,182,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_1 (Reshape)         (None, 1, 207)            0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 1, 1470)          4163040   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 1470)             9732870   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 735)               1081185   \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 35, 21, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,977,095\n",
      "Trainable params: 14,977,095\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "4/4 [==============================] - 58s 2s/step - g_loss: 0.8284 - d_loss: 2.6707\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 8s 2s/step - g_loss: 1.2327 - d_loss: 1.1411\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 8s 2s/step - g_loss: 0.5688 - d_loss: 0.7669\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 8s 2s/step - g_loss: 1.0802 - d_loss: 0.7170\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 10s 2s/step - g_loss: 0.8105 - d_loss: 0.7140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x217e629c9a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=create_discriminator_model(), generator=create_generator_model(), latent_dim= LATENT_DIM, num_classes=NUM_CLASSES\n",
    "  )\n",
    "cond_gan.compile(\n",
    "  d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "  g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "  loss_fn=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    ")\n",
    "\n",
    "#Tensorboard\n",
    "#TENSORBOARD_LOG_DIR = \"data/logs/tensorboard/\"+EXPERIMENT_NAME+\"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=TENSORBOARD_LOG_DIR, histogram_freq=1)\n",
    "\n",
    "\n",
    "cond_gan.fit(dataset, epochs = EPOCHS)#,callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRFKPLKNVRIGLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KFKPLYFRYGSYVVKPAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GFEDLPAGKVEWLWMMIPAAQKAMGD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DALTLGLFGVGQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MKH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MSLKLWLRVQKLMCAW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IPKKLWYRWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sequence\n",
       "0              GRFKPLKNVRIGLC\n",
       "1                          IK\n",
       "2          KFKPLYFRYGSYVVKPAQ\n",
       "3  GFEDLPAGKVEWLWMMIPAAQKAMGD\n",
       "4                         IFR\n",
       "5                DALTLGLFGVGQ\n",
       "6                         MKH\n",
       "7            MSLKLWLRVQKLMCAW\n",
       "8                  IPKKLWYRWS\n",
       "9                          CK"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_gan.generate_class_random(10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "9.1 Validaci√≥n del modelo final.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
